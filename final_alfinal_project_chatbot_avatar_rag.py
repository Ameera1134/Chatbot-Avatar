# -*- coding: utf-8 -*-
"""Final_AlFinal_Project_Chatbot_Avatar_RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sei5qFSgrmfM8qY6gQ_7XS8fk4YcEsdo

# Setting up
"""

!pip install unstructured

!pip install -U transformers huggingface_hub sentence-transformers langchain

!pip install --upgrade transformers huggingface_hub sentence-transformers
!pip install langchain  # إذا كنت تستخدم LangChain

!pip install langchain_core
!pip install langchain_groq
!pip install bs4

!pip install python-dotenv

!pip install langchain-huggingface

!pip install langchain-community

!pip install selenium

!pip install langchain_chroma

!unzip /content/pages.zip -d /content/

import requests
from bs4 import BeautifulSoup

import os
from dotenv import load_dotenv
load_dotenv()

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq

from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma

from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever

from langchain_core.prompts import MessagesPlaceholder
from langchain_core.messages import AIMessage,HumanMessage

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from google.colab import userdata
groq_api_key = userdata.get('GROQ_API_KEY')

if groq_api_key:
    print("GROQ API key loaded successfully.")
else:
    print("GROQ API key not found. Please set the GROQ_API_KEY environment variable.")

hf_token = userdata.get("HF_TOKEN")
if hf_token is None:
    hf_token = "HF_TOKEN"  # Replace with your actual Hugging Face token or a suitable default
    print("Warning: HF_TOKEN not found in environment variables. Using default value.")

os.environ['HF_TOKEN'] = hf_token

"""# Data Ingestion"""

# urls_products = {
#       'https://electroon.sa',
#       'https://electroon.sa/Electron-Offers/c2124320077',
#       'https://electroon.sa/الأجهزة-الذكية/c1751856040',
#       'https://electroon.sa/الأجهزة-الذكية/c1751856040',
#       'https://electroon.sa/منتجات-ابل/c1841051467',
#       'https://electroon.sa/منتجات-ابل/c1841051467',
#       'https://electroon.sa/IPhone/c582057279',
#       'https://electroon.sa/اكسسوارات-الآيفون/c486648014',
#       'https://electroon.sa/أيباد/c118439741',
#       'https://electroon.sa/ملحقات-الأيباد/c1102931345',
#       'https://electroon.sa/سماعات-أبل/c758408021',
#       'https://electroon.sa/ملحقات-السماعات/c1350987161',
#       'https://electroon.sa/جوالات-هونر/c1559625973',
#       'https://electroon.sa/جوالات-شاومي/c615566627',
#       'https://electroon.sa/جوالات-سامسونج/c446259485',
#       'https://electroon.sa/الأجهزة-المنزلية/c544848292',
#       'https://electroon.sa/الأجهزة-المنزلية/c544848292',
#       'https://electroon.sa/أقفال-الباب-الذكية/c713304999',
#       'https://electroon.sa/شاشات-التلفزيون/c1355890182',
#       'https://electroon.sa/أجهزة-العرض/c1277000938',
#       'https://electroon.sa/المكانس-الذكية/c1746288180',
#       'https://electroon.sa/التوصيلات-الكهربائية/c1006309179',
#       'https://electroon.sa/ملحقات-المنزل-الأخرى/c888446920',
#       'https://electroon.sa/أجهزة-الشحن/c1572205274',
#       'https://electroon.sa/أجهزة-الشحن/c1572205274',
#       'https://electroon.sa/باور-بانك/c781323511',
#       'https://electroon.sa/الشواحن/c1121287123',
#       'https://electroon.sa/الشواحن/c1121287123',
#       'https://electroon.sa/شواحن-جدارية/c2089347984',
#       'https://electroon.sa/شواحن-لاسلكي/c1780435091',
#       'https://electroon.sa/منصات-الشحن/c1672451486',
#       'https://electroon.sa/شواحن-السيارات/c1314196113',
#       'https://electroon.sa/كيابل-شحن/c612487953',
#       'https://electroon.sa/كيابل-شحن/c612487953',
#       'https://electroon.sa/Type-C-cables/c1804676496',
#       'https://electroon.sa/كيابل-Lightning/c798101979',
#       'https://electroon.sa/كيابل-Micro/c2038378532',
#       'https://electroon.sa/ملحقات-بلاي-ستيشن/c1489910719',
#       'https://electroon.sa/السماعات/c1722993416',
#       'https://electroon.sa/السماعات/c1722993416',
#       'https://electroon.sa/سماعات-رأس/c1987272947',
#       'https://electroon.sa/مكبرات-صوت/c304525053',
#       'https://electroon.sa/سماعات-لأسلكية/c1642414461',
#       'https://electroon.sa/JBL/c1729550645',
#       'https://electroon.sa/الساعات/c838005735',
#       'https://electroon.sa/الساعات/c838005735',
#       'https://electroon.sa/ساعات-ذكية/c211209092',
#       'https://electroon.sa/ملحقات-الساعات/c1584654981',
#       'https://electroon.sa/ملحقات-الحاسوب/c118787460',
#       'https://electroon.sa/ملحقات-السيارات/c1534357102',
#       'https://electroon.sa/ملحقات-السيارات/c1534357102',
#       'https://electroon.sa/كاميرات-داش-كام/c340777482',
#       'https://electroon.sa/منتجات-الصحة-والرياضة/c2131834600',
#       'https://electroon.sa/أدوات-يومية/c1046728355',
#       'https://electroon.sa/منتجات-iWin/c150847693',
#       'https://electroon.sa/الأكثر-مبيعا/c1524297678',
#       'https://electroon.sa/redirect/categories/2124320077',
#       'https://electroon.sa/redirect/categories/118787460',
#       'https://electroon.sa/redirect/categories/1534357102',
#       'https://electroon.sa/redirect/categories/2131834600',
#       'https://electroon.sa/redirect/categories/1987272947',
#       'https://electroon.sa/redirect/categories/211209092',
#       'https://electroon.sa/redirect/categories/544848292',
#       'https://electroon.sa/redirect/categories/1572205274',
#       'https://electroon.sa/redirect/categories/1489910719',
#       'https://electroon.sa/redirect/categories/1046728355',
#       'https://electroon.sa/redirect/categories/1751856040',
#       'https://electroon.sa/redirect/categories/544848292',
#       'https://electroon.sa/redirect/categories/304525053',
#       'https://electroon.sa/redirect/categories/838005735',
#       'https://electroon.sa/redirect/categories/118787460',
#       'https://electroon.sa/redirect/categories/150847693',
#       'https://electroon.sa/redirect/categories/2131834600',
#       'https://electroon.sa/سامسونج/brand-119142833',
#       'https://electroon.sa/ابل/brand-893180592',
#       'https://electroon.sa/سيلفر-كريست/brand-1532476343',
#       'https://electroon.sa/بورودو/brand-160079030',
#       'https://electroon.sa/هوم-بست/brand-1068268981',
#       'https://electroon.sa/مكانس-يوفي/brand-335167403',
#       'https://electroon.sa/hoto/brand-1176309930',
#       'https://electroon.sa/بيلكن/brand-1949364649',
#       'https://electroon.sa/باورلوجي/brand-443273896',

# }

# import os
# from selenium import webdriver
# from selenium.webdriver.chrome.options import Options
# import time



# # --- إنشاء مجلد لتخزين الملفات ---
# output_folder = "pages"
# os.makedirs(output_folder, exist_ok=True)

# options = Options()
# options.add_argument('--headless')
# options.add_argument('--no-sandbox')
# options.add_argument('--disable-dev-shm-usage')

# driver = webdriver.Chrome(options=options)

# for i, url in enumerate(urls_products, start=1):
#     driver.get(url)
#     time.sleep(5)

#     html = driver.page_source

#     # اسم الملف بالترتيب
#     filepath = os.path.join(output_folder, f"page_{i}.html")

#     with open(filepath, "w", encoding="utf-8") as f:
#         f.write(html)

#     print(f"✅ Saved {url} -> {filepath}")

# driver.quit()

"""# Start again:"""

# from google.colab import drive
# drive.mount('/content/drive')

import os

# تحديد مسار المجلد في Google Drive
folder_path = '/content/pages'

# التحقق مما إذا كان المجلد موجودًا
if os.path.exists(folder_path):
    # جلب قائمة الملفات والمجلدات داخل المجلد
    files_and_folders = os.listdir(folder_path)

    # طباعة القائمة للتحقق
    print(f"العناصر الموجودة في المجلد {folder_path} هي:")
    for item in files_and_folders:
        print(item)
else:
    print(f"المجلد {folder_path} غير موجود. يرجى التأكد من صحة المسار وأن Google Drive مُثبت بشكل صحيح.")

from langchain_community.document_loaders import PyPDFLoader

# Load the PDF
pdf_path = "/content/content_ele.pdf"  # Make sure this path is correct
loader = PyPDFLoader(pdf_path)
pdf_documents = loader.load()
print(f"Loaded {len(pdf_documents)} pages from PDF.")

pdf_documents

# import os

# # تحديد مسار المجلد
# folder_path = '/content/pages'

# files_and_folders = os.listdir(folder_path)

# # طباعة القائمة للتحقق
# print(f"العناصر الموجودة في المجلد {folder_path} هي:")
# print(files_and_folders)

print(type(files_and_folders))

files = sorted(os.listdir(folder_path))

for file in files:
    if file.endswith(".html"):   # تأكد أنه ملف HTML
        filepath = os.path.join(folder_path, file)

        with open(filepath, "r", encoding="utf-8") as f:
            html = f.read()

        print(f"✅ Opened {filepath}, length = {len(html)} chars")

html

from bs4 import BeautifulSoup

# لما يكون المنتج غير متوفر (Out of Stock).
# ✅ كيف نضيف availability:


def extract_products(html):
    soup = BeautifulSoup(html, "html.parser")
    products = []

    for card in soup.find_all("custom-salla-product-card"):
        # name
        name_tag = card.find("h3", class_="s-product-card-content-title")
        name = name_tag.get_text(strip=True) if name_tag else ""

        # link
        link_tag = name_tag.find("a") if name_tag else None
        link = link_tag["href"] if link_tag else ""

        # category
        category_tag = card.find("span", class_="s-product-card-category")
        category = category_tag.get_text(strip=True) if category_tag else ""

        # brand
        brand_tag = card.find("span", class_="s-product-card-brand")
        brand = brand_tag.get_text(strip=True) if brand_tag else ""

        # price
        price_tag = card.find("h4", class_="s-product-card-price")
        price = price_tag.get_text(strip=True) if price_tag else ""

        # old price
        old_price_tag = card.find("span", class_="s-product-card-price-before")
        old_price = old_price_tag.get_text(strip=True) if old_price_tag else ""

        # availability (افتراضياً متوفر)
        availability = "متوفر"

        # مثال: لو فيه span فيه كلمة "غير متوفر"
        unavailable_tag = card.find("span", string=lambda text: text and "غير متوفر" in text)
        if unavailable_tag:
            availability = "غير متوفر"

        # مثال ثاني: لو فيه زر معطل (disabled)
        button_tag = card.find("button", disabled=True)
        if button_tag:
            availability = "غير متوفر"

        products.append({
            "name": name,
            "link": link,
            "category": category,
            "brand": brand,
            "price": price,
            "old_price": old_price,
            "availability": availability
        })

    return products

all_products = []

for file in files:
    if file.endswith(".html"):
        filepath = os.path.join(folder_path, file)
        with open(filepath, "r", encoding="utf-8") as f:
            html = f.read()

        # Extract products from this page and add to the full list
        page_products = extract_products(html)
        all_products.extend(page_products)

products_data = ""
for p in all_products:
    products_data += f"اسم المنتج: {p.get('name', 'غير معروف')}\n"
    products_data += f"السعر: {p.get('price', 'غير محدد')}\n"
    products_data += f"الرابط: {p.get('link', 'لا يوجد رابط')}\n"
    products_data += f"المخزون: {p.get('availability', 'غير معروف')}\n\n"

print(all_products[0].keys())

from bs4 import BeautifulSoup

html = "<html>...</html>"  # صفحة المنتج
soup = BeautifulSoup(html, "html.parser")

products_data = ""
for card in soup.find_all("div", class_="product-card"):
    name = card.find("h3").text.strip()
    price = card.find("span", class_="price").text.strip()
    link = card.find("a")["href"]
    stock = "متوفر" if "in-stock" in card["class"] else "نفذ"

    products_data += f"اسم المنتج: {name}\nالسعر: {price}\nالرابط: {link}\nالمخزون: {stock}\n\n"

"""# Splitter to chunks of docs"""

from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
import json

# ----- منتجات -----
product_docs = [
    Document(page_content=json.dumps(product, ensure_ascii=False), metadata={"source": "products"})
    for product in all_products
]

# ----- سياسات -----
# Extract text content from PDF documents
# استخدم:
policy_docs = [
    Document(page_content=doc.page_content, metadata={"source": "policies", "page": i})
    for i, doc in enumerate(pdf_documents)
]

# ----- دمج -----
all_docs = product_docs + policy_docs

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=200,
    chunk_overlap=50
)

split_docs = text_splitter.split_documents(all_docs)
print(f"Total chunks: {len(split_docs)}")

split_docs

"""# Embeddings"""

embeddings = HuggingFaceEmbeddings(model_name="Omartificial-Intelligence-Space/Arabic-Triplet-Matryoshka-V2")

"""# Vector Store"""

from langchain.vectorstores import Chroma

vectorstore = Chroma.from_documents(
    documents=split_docs,
    embedding=embeddings
)

# Define retriever in the global scope
retriever = vectorstore.as_retriever()

# الاستعلام عن كلمة "ضمان"
query = "هل يوجد ضمان؟"

docs = retriever.invoke(query)

for i, d in enumerate(docs, 1):
    print(f"--- Document {i} ---")
    print(d.page_content[:])
    print("Metadata:", d.metadata)
    print()

"""# LLM Model"""

llm=ChatGroq(groq_api_key=groq_api_key,model_name="llama-3.3-70b-versatile", temperature=0)

"""# Prompt"""

product_prompt = (
    "أنت مساعد ذكي للمبيعات باللغة العربية فقط، واسمك مُعين. "
    "اعتمد على المعلومات التالية ({context}) للإجابة على أسئلة العملاء بدقة. "
    "عند سؤال العميل عن أي منتج، أعطه دائمًا: "
    "- اسم المنتج بالضبط "
    "- السعر بالريال السعودي "
    "- رابط مباشر للمنتج من السياق فقط "
    "لا تذكر اسم الموقع ولا تختلق روابط جديدة. "
    "إذا لم يكن المنتج متوفرًا أو نفد من المخزون، أخبر العميل بذلك بوضوح ثم اقترح بدائل مقترحة مشابهة. "
    "اجعل الإجابات قصيرة، موجزة، ومنظمة بصيغة نقاط مثل: "
    "اسم المنتج: ...\nالسعر: ...\nالرابط: ..."
)


policy_prompt = (
    "أنت مساعد خدمة العملاء بالذكاء الاصطناعي، واسمك مُعين. "
    "تعمل في متجر إلكتروني وتقدم إجابات دقيقة وسريعة للعملاء باللغة العربية فقط. "
    "({context}) المتعلقة بالشحن، الدفع، الاسترجاع، الضمان، الخصوصية، وأوقات الدوام. "
    "قدم التفاصيل الدقيقة الموجودة في السياسات حول الشحن، الرسوم، المدة، أوقات العمل، الاسترجاع، الاستبدال، الضمان وسياسات الخصوصية. "
    "إذا لم توجد المعلومات المطلوبة ، أجب بصراحة: 'لا تتوفر معلومات حول ذلك  .' "
    "حافظ على إجاباتك قصيرة وموجزة، لا تتجاوز ثلاث جمل. "
    "لا تضف أي أمثلة أو خدمات خارجية غير موجودة  ."
    "إذا سأل العميل عن طريقة دفع، اعرض فقط المعلومات الموجودة في الملف حول طرق الدفع. لا تذكر الاسترجاع أو سياسات أخرى إلا إذا سأل عنها مباشرة."
    "إذا سأل العميل عن وسيلة دفع محددة مثل تابي أو تمارا ولم تذكر في الملف، اعرض فقط المعلومات المتوفرة عن وسائل الدف  مع التنويه بعدم وجود تفاصيل محددة عن الطريقة المذكورة."
    "اعرض أي معلومات عن طرق الدفع موجودة في الملف حتى لو لم تذكر الطريقة المحددة مثل تابي أو تمارا."
    "إذا سأل العميل عن وسيلة دفع محددة مثل تابي أو تمارا ولم تذكر في الملف، اعرض المعلومات المتوفرة عن طرق الدفع العامة في السياسات، مع التنويه بعدم وجود تفاصيل عن الطريقة المحددة."

)

def classify_question(question: str) -> str:
    # كلمات مفتاحية للسياسات
    policy_keywords = ["شحن", "استرجاع", "استبدال", "ضمان", "دفع", "تابي", "تمارا", "الخصوصية", "الدوام"]
    if any(word in question for word in policy_keywords):
        return "policy"
    return "product"

"""# Retriever"""

from langchain_core.prompts import ChatPromptTemplate

def make_rag_chain(question, llm, vectorstore):
    # 1. نحدد نوع السؤال
    q_type = classify_question(question)

    # 2. نختار البرومبت المناسب وننشئ PromptTemplate
    if q_type == "product":
        prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", product_prompt),
                ("human", "{input}"),
            ]
        )
    else:
        prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", policy_prompt),
                ("human", "{input}"),
            ]
        )


    # 3. نبني الـ chain
    retriever = vectorstore.as_retriever()
    qa_chain = create_stuff_documents_chain(llm, prompt_template) # Use the created prompt_template
    rag_chain = create_retrieval_chain(retriever, qa_chain)

    return rag_chain

results = vectorstore.similarity_search("ضمان", k=3)
for r in results:
    print(r.page_content)

"""# Response form the LLM"""

question = "هل يوجد ضمان؟"
rag_chain = make_rag_chain(question, llm, vectorstore)
response = rag_chain.invoke({"input": question})
print(response["answer"])

question = " شاحن ايفون"
rag_chain = make_rag_chain(question, llm, vectorstore)
response = rag_chain.invoke({"input": question})
print(response["answer"])

"""# Audio :"""

!pip install gTTS pydub

from gtts import gTTS
from pydub.playback import play
from IPython.display import Audio , display
import tempfile
import re

def clean_and_tts(response_text, lang="ar"):
    # حذف الروابط
    cleaned_text = re.sub(r'http\S+', '', response_text)
    lines = [line.strip() for line in cleaned_text.split("\n") if line.strip()]

    product = ""
    price = ""

    # استخراج المنتج والسعر
    for line in lines:
        if "اسم المنتج" in line and not product:
            product = line.replace("اسم المنتج:", "").strip()
        elif "السعر" in line and not price:
            price = line.replace("السعر:", "").strip()

    # نص نهائي للقراءة
    if product and price:
        final_text = f"{product}.\nالسعر هو {price}."
    elif product:
        final_text = product
    elif price:
        final_text = f"السعر هو {price}."
    elif lines:
        final_text = "\n".join(lines)
    else:
        final_text = response_text

    # تحويل النص لصوت
    tts = gTTS(text=final_text, lang=lang)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        # نعرض الصوت لتشغيله مباشرة
        display(Audio(fp.name, autoplay=True))

    return final_text  # لو حبيت ترجع النص للعرض أو المراجعة

# Install gltf-pipeline
# !npm install -g gltf-pipeline

import requests

# رابط الافتار الجديد من Ready Player Me
avatar_url = "https://models.readyplayer.me/68bb8865c03601654534f439.glb"

# تحميل الملف .glb
glb_file = "avatar_me.glb"
with requests.get(avatar_url, stream=True) as r:
    r.raise_for_status() # Raise an exception for bad status codes
    with open(glb_file, "wb") as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)

print(f"تم تحميل الافتار وحفظه في: {glb_file}")

# # تحويل glb -> gltf باستخدام gltf-pipeline
# gltf_json_file = "avatar_new1.gltf"
# # Use the installed gltf-pipeline command
# !gltf-pipeline -i {glb_file} -o {gltf_json_file}

# print(f"تم تحويل الافتار وحفظه بصيغة GLTF في: {gltf_json_file}")

!pip install streamlit

!pip install streamlit pyngrok

import streamlit as st
from gtts import gTTS
import base64

# ---- هنا تربط الـ RAG Chain مع الداتا سيت الخاصة بك ----
# افترض أن rag_chain جاهز
# من قبل: rag_chain = make_rag_chain(llm, vectorstore)

st.title("محادثة مع الأفاتار")

user_text = st.text_input("اكتب سؤالك هنا:")

if st.button("إرسال") and user_text:
    # ----- 1. احصل على الرد من الداتا سيت باستخدام RAG ----
    try:
        response = rag_chain.invoke({"input": user_text})
        bot_reply = response["answer"]
    except Exception as e:
        bot_reply = f"حدث خطأ عند استدعاء RAG: {e}"

    # ----- 2. تحويل الرد لصوت -----
    tts = gTTS(bot_reply, lang="ar")
    tts.save("reply.mp3")
    audio_file = open("reply.mp3", "rb")
    st.audio(audio_file.read(), format='audio/mp3')

    # ----- 3. عرض الأفاتار 3D مع الصوت -----
    with open("avatar_me.glb", "rb") as f:
        glb_content = base64.b64encode(f.read()).decode("utf-8")

    avatar_html = f"""
    <div id="container" style="width:400px; height:400px;"></div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script>
    const container = document.getElementById('container');
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(60, container.clientWidth / container.clientHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({{antialias:true}});
    renderer.setSize(container.clientWidth, container.clientHeight);
    container.appendChild(renderer.domElement);
    const loader = new THREE.GLTFLoader();
    loader.load(
        'data:model/gltf+json;base64,{glb_content}',
        function(gltf) {{ scene.add(gltf.scene); }},
        undefined,
        function(error) {{ console.error(error); }}
    );
    camera.position.set(0,1.5,2);
    function animate() {{ requestAnimationFrame(animate); renderer.render(scene,camera); }}
    animate();
    </script>
    """
    st.components.v1.html(avatar_html, height=450)

from IPython.display import display, HTML
import base64

def display_avatar_with_audio(glb_path, audio_path):
    with open(glb_path, 'rb') as f:
        glb_content = base64.b64encode(f.read()).decode('utf-8')

    with open(audio_path, 'rb') as f:
        audio_content = base64.b64encode(f.read()).decode('utf-8')

    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Avatar with Audio</title>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    </head>
    <body style="margin:0; background:#111; display:flex; flex-direction:column; align-items:center;">
        <div id="container" style="width: 800px; height: 800px;"></div>
        <audio id="audioPlayer" controls autoplay>
            <source src="data:audio/mpeg;base64,{audio_content}" type="audio/mpeg">
        </audio>

        <script>
            const container = document.getElementById('container');
            const scene = new THREE.Scene();
            const camera = new THREE.PerspectiveCamera(60, container.clientWidth / container.clientHeight, 0.1, 1000);
            const renderer = new THREE.WebGLRenderer({{antialias:true}});
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(container.clientWidth, container.clientHeight);
            container.appendChild(renderer.domElement);

            const loader = new THREE.GLTFLoader();
            let neck, head, leftEye, rightEye;

            loader.load(
                'data:model/gltf+json;base64,{glb_content}',
                function (gltf) {{
                    const avatar = gltf.scene;
                    avatar.scale.set(5, 5, 3);
                    avatar.position.set(0, -1, 0);
                    scene.add(avatar);

                    neck = avatar.getObjectByName("Neck");
                    head = avatar.getObjectByName("Wolf3D_Head");
                    leftEye = avatar.getObjectByName("EyeLeft");
                    rightEye = avatar.getObjectByName("EyeRight");

                    // ---- إخفاء اليدين ----
                    const handNodes = [
                        "RightHand","LeftHand","RightHandIndex1","RightHandIndex2","RightHandIndex3",
                        "RightHandMiddle1","RightHandMiddle2","RightHandMiddle3",
                        "RightHandRing1","RightHandRing2","RightHandRing3",
                        "RightHandPinky1","RightHandPinky2","RightHandPinky3",
                        "RightHandThumb1","RightHandThumb2","RightHandThumb3",
                        "LeftHandIndex1","LeftHandIndex2","LeftHandIndex3",
                        "LeftHandMiddle1","LeftHandMiddle2","LeftHandMiddle3",
                        "LeftHandRing1","LeftHandRing2","LeftHandRing3",
                        "LeftHandPinky1","LeftHandPinky2","LeftHandPinky3",
                        "LeftHandThumb1","LeftHandThumb2","LeftHandThumb3",
                        "RightHand","LeftHand","Wolf3D_Hands"
                    ];

                    handNodes.forEach(function(name){{
                        const node = avatar.getObjectByName(name);
                        if(node) node.visible = false;
                    }});
                }},
                undefined,
                function (error) {{
                    console.error('Error loading GLTF:', error);
                }}
            );

            camera.position.set(0, 1.8, 3);

            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            scene.add(ambientLight);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(0, 3, 3);
            scene.add(directionalLight);

            // ---- تحليل الصوت ----
            const audioElement = document.getElementById("audioPlayer");
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const track = audioCtx.createMediaElementSource(audioElement);
            const analyser = audioCtx.createAnalyser();
            analyser.fftSize = 256;
            track.connect(analyser);
            analyser.connect(audioCtx.destination);
            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            let blinkTimer = 0;

            function animate() {{
                requestAnimationFrame(animate);

                analyser.getByteFrequencyData(dataArray);
                const volume = dataArray.reduce((a,b)=>a+b)/dataArray.length/256;

                // ---- حركة الرأس ----
                if(neck){{
                    neck.rotation.x = volume * 0.2;
                }}

                // ---- حركة الفم ----
                if(head && head.morphTargetInfluences){{
                    head.morphTargetInfluences[0] = volume * 2.0;
                }}

                // ---- رمش العيون ----
                blinkTimer++;
                if(blinkTimer > 150 + Math.random()*100 && leftEye && rightEye){{
                    blinkTimer = 0;
                    leftEye.scale.y = 0.05;
                    rightEye.scale.y = 0.05;
                    setTimeout(()=>{{
                        leftEye.scale.y = 1;
                        rightEye.scale.y = 1;
                    }}, 150);
                }}

                renderer.render(scene, camera);
            }}
            animate();

            window.addEventListener('resize', ()=>{{
                renderer.setSize(container.clientWidth, container.clientHeight);
                camera.aspect = container.clientWidth / container.clientHeight;
                camera.updateProjectionMatrix();
            }});
        </script>
    </body>
    </html>
    """

    display(HTML(html_content))

from langchain.chains import RetrievalQA
llm=ChatGroq(groq_api_key=groq_api_key,model_name="llama-3.3-70b-versatile", temperature=0)
rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever= vectorstore.as_retriever())

text = "أهلاً وسهلاً، هل يوجد هل يوجد شاحن ايفون"
response = rag_chain.run(text)

tts = gTTS(response, lang="ar")
tts.save("voice.mp3")

from gtts import gTTS

!pip install pygltflib

!pip install fastapi uvicorn

# from pygltflib import GLTF2

# def print_gltf_objects(gltf_path):
#     gltf = GLTF2().load_binary(gltf_path)
#     print("----- قائمة النودات في الـ GLB -----")
#     for i, node in enumerate(gltf.nodes):
#         print(f"Node {i}: {node.name}")

# # استبدل بالمسار الصحيح لملف GLB الخاص بك
# print_gltf_objects("avatar_me.glb")

display_avatar_with_audio("avatar_me.glb", "voice.mp3")

import gradio as gr
from gtts import gTTS
import tempfile
import base64
import os

# Assume rag_chain is defined in previous cells

def respond(message, history):
    # Get response from RAG chain
    response = rag_chain.invoke({"input": message})
    response_text = response['answer']

    # Convert response to audio
    tts = gTTS(response_text, lang="ar")
    temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3").name
    tts.save(temp_audio_file)

    # Encode GLB for HTML display
    try:
        with open("avatar_me.glb", "rb") as f:
            glb_content = base64.b64encode(f.read()).decode("utf-8")
    except FileNotFoundError:
        return "Error: avatar_me.glb not found.", None

    # Create HTML content with avatar and audio
    avatar_html = f"""
    <div id="container" style="width:400px; height:400px;"></div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script>
        const container = document.getElementById('container');
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(60, container.clientWidth/container.clientHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({{antialias:true}});
        renderer.setSize(container.clientWidth, container.clientHeight);
        container.appendChild(renderer.domElement);

        const loader = new THREE.GLTFLoader();
        loader.load(
            'data:model/gltf+json;base64,{glb_content}',
            function(gltf) {{
                const avatar = gltf.scene;
                avatar.scale.set(2,2,2);
                scene.add(avatar);
                camera.position.set(0,1.8,3);
            }},
            undefined,
            function(error) {{ console.error(error); }}
        );

        const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
        directionalLight.position.set(0,3,3);
        scene.add(directionalLight);

        function animate() {{
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }}
        animate();
    </script>
    """

    # Return both the text response and the audio file path
    return response_text, temp_audio_file, avatar_html


# Create Gradio interface
iface = gr.Interface(
    fn=respond,
    inputs="text",
    outputs=[gr.Textbox(label="Response"), gr.Audio(label="Audio Response"), gr.HTML(label="Avatar")],
    title="Avatar Chatbot",
    description="Chat with the avatar using the loaded data."
)

iface.launch(debug=True)

# !pip install pyassimp requests

# import requests
# import json
# import os

"""# Adding Chat History

"""

# system_prompt
contextualize_q_system_prompt = (
    "بناءً على سجل المحادثة والسؤال الأخير من المستخدم، "
    "والذي قد يشير إلى سياق في المحادثة، "
    "قم بصياغة سؤال مستقل يمكن فهمه بدون الاعتماد على سجل المحادثة. "
    "لا تُجب على السؤال، فقط أعد صياغته إذا لزم الأمر، وإلا أعده كما هو."
    "لا تذكر اسم الموقع (ELECTRON)"

)

# General_prompt
contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", contextualize_q_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)

history_aware_retriever=create_history_aware_retriever(llm,retriever,contextualize_q_prompt)
history_aware_retriever

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)

question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)
rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)

"""# chat_history *"""

from langchain.schema import HumanMessage, AIMessage
import tempfile
import re
from gtts import gTTS
from pydub.playback import play
from IPython.display import Audio , display

# نفترض أن chat_history معرف مسبقًا كـ list
chat_history = []

def clean_and_tts(response_text, lang="ar"):
    # حذف الروابط
    cleaned_text = re.sub(r'http\S+', '', response_text)
    lines = [line.strip() for line in cleaned_text.split("\n") if line.strip()]

    product = ""
    price = ""

    # استخراج المنتج والسعر
    for line in lines:
        if "اسم المنتج" in line and not product:
            product = line.replace("اسم المنتج:", "").strip()
        elif "السعر" in line and not price:
            price = line.replace("السعر:", "").strip()

    # نص نهائي للقراءة
    if product and price:
        final_text = f"{product}.\nالسعر هو {price}."
    elif product:
        final_text = product
    elif price:
        final_text = f"السعر هو {price}."
    elif lines:
        final_text = "\n".join(lines)
    else:
        final_text = response_text


    # تحويل النص لصوت وحفظه في ملف مؤقت
    tts = gTTS(text=final_text, lang=lang)
    temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3").name
    tts.save(temp_audio_file)

    return final_text, temp_audio_file


def ask_and_tts(question, chat_history, lang="ar"):
    # استدعاء RAG
    response = rag_chain.invoke({"input": question, "chat_history": chat_history})
    response_text = response['answer']

    # تشغيل TTS وحفظ الملف
    final_text, audio_file_path = clean_and_tts(response_text, lang=lang)

    # عرض الافتار مع الصوت
    display_avatar_with_audio("avatar_new.gltf", audio_file_path)

    # تحديث الهيستوري
    chat_history.extend([
        HumanMessage(content=question),
        AIMessage(content=response_text)
    ])

    # يمكنك حذف الملف المؤقت إذا لم تعد بحاجة إليه لاحقًا
    # os.remove(audio_file_path)

    # إعادة الجواب لو احتجت تستخدمه لاحقًا
    return response_text

answer1 = ask_and_tts("  بكم بكج ملحقات الايباد ", chat_history)

answer2 = ask_and_tts("how much is Acer Aspire ES1-732 Black, 17.3 HD+, Celeron, N3350, 4GB, 1TB, Windows 10 Home?", chat_history)

answer3 = ask_and_tts("هل يوجد ضمان؟", chat_history)

print(chat_history)

"""# session_history(for many chats)"""

store = {}


def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
    output_messages_key="answer",
)

"""# Test history conversational of rag"""

conversational_rag_chain.invoke(
    {"input": "how much is 	Acer Aspire ES1-732 Black, 17.3 HD+, Celeron, N3350, 4GB, 1TB, Windows 10 Home?"},
    config={
        "configurable": {"session_id": "abc123"}
    },  # constructs a key "abc123" in `store`.
)["answer"]

conversational_rag_chain.invoke(
    {"input": "how much is 	Acer Aspire ES1-732 Black, 17.3 HD+, Celeron, N3350, 4GB, 1TB, Windows 10 Home?"},
    config={"configurable": {"session_id": "abc123"}},
)["answer"]

store

conversational_rag_chain.invoke(
    {"input": "What are common ways of doing it?"},
    config={"configurable": {"session_id": "chat2"}},
)["answer"]

store['abc123']

messages=store['abc123'].messages

for message in messages:
    print(message.content)

store['chat2']



!pip install arabic_reshaper

question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)
rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)

question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)
rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)

from langchain.vectorstores import Chroma

vectorstore = Chroma.from_documents(
    documents=split_docs,
    embedding=embeddings
)